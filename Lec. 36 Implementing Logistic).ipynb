{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dca9d66d-3caf-4d3a-b27d-c1630b6d6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log, dot, exp, shape, sum\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eb26d4e4-14db-4f40-933b-50a557a82f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AmazonMobileDataCleaned3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7c09d2d1-953e-49f9-8755-141322112b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanedreview_3</th>\n",
       "      <th>decision_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samsung awhile absolute doo doo read review de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>due software issue nokia sprint phones text me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great reliable phone also purchased phone sams...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love phone really need one didnt expect price ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone great every purpose offers except day bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cleanedreview_3  decision_2\n",
       "0  samsung awhile absolute doo doo read review de...           1\n",
       "1  due software issue nokia sprint phones text me...           1\n",
       "2  great reliable phone also purchased phone sams...           1\n",
       "3  love phone really need one didnt expect price ...           1\n",
       "4  phone great every purpose offers except day bo...           1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "276dde0f-68bb-45c4-9d33-bcb0d9b9a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data['decision_2'].values.reshape(-1,1)   #  output y is separated in a list called as label\n",
    "feedback = data.drop(['decision_2'], axis = 1)    #input x is separated in form of Dataframe only called as data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d7f65236-dccf-48ce-ad70-965ad6c303cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label), type(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ec8f772d-9cda-457a-9813-7f6fb0ab385f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71909, 1), (71909, 1))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape, feedback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9eed09d2-c375-45ac-9fa1-de0807d27396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validation, testing data\n",
    "\n",
    "inputtrain, inputtest, outputtrain, outputtest = train_test_split(feedback, label, test_size = 0.2, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3c7d900b-bb9a-4f47-b0f6-2eab18d846c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, numpy.ndarray)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputtrain), type(outputtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3178c938-3aca-43f9-af54-0be577c6f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanedreview_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55463</th>\n",
       "      <td>fired works well verizon account replaced sams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66894</th>\n",
       "      <td>price quality ratio good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47182</th>\n",
       "      <td>awesome phone lot creative features easy use s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50817</th>\n",
       "      <td>received phone decent condition notice mins us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>love ir nice phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67903</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>phone great shape works perfectly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>love new samsung galaxy cheaply obtained still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64641</th>\n",
       "      <td>phone beautiful unboxing joy huge screen great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20390</th>\n",
       "      <td>love love love bought dec still great slow tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57527 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleanedreview_3\n",
       "55463  fired works well verizon account replaced sams...\n",
       "66894                           price quality ratio good\n",
       "47182  awesome phone lot creative features easy use s...\n",
       "50817  received phone decent condition notice mins us...\n",
       "60333                                 love ir nice phone\n",
       "...                                                  ...\n",
       "67903                                               good\n",
       "24479                  phone great shape works perfectly\n",
       "8915   love new samsung galaxy cheaply obtained still...\n",
       "64641  phone beautiful unboxing joy huge screen great...\n",
       "20390  love love love bought dec still great slow tim...\n",
       "\n",
       "[57527 rows x 1 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eee6e57e-f879-4605-87f9-3b1c4c8dbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inputtrain['cleanedreview_3'].values\n",
    "# y is already an array\n",
    "Y = outputtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8ad7985f-73ac-45dd-85f0-4b7f41cf7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fired works well verizon account replaced samsung model swap sim card log google account',\n",
       "       'price quality ratio good',\n",
       "       'awesome phone lot creative features easy use sounds great takes amazing photos also write texts crop animated photos stylus',\n",
       "       ...,\n",
       "       'love new samsung galaxy cheaply obtained still learning great features',\n",
       "       'phone beautiful unboxing joy huge screen great overall ecstatic purchase seconds started reading instructions came across small factor huawei cleverly chose not disclose customers product description quote dual card dual standby single pass means cannot use sim cards calls data services simultaneously not dual sim owned several real dual sim phones every one capability able make answer calls use data services simultaneously whole purpose dual sim wanted glamorized sim holder second sim exactly phone really would bought bedazzled box put not phone completely missadvertised something not want phone actually offers fully functional dual sim capability not buy phone quite frankly without dual sim function nothing paperweight thats not strictly true paperweight exactly level use not masquerade something not second without doubt last huawei purchase could give no stars happily would pathetic',\n",
       "       'love love love bought dec still great slow times even tells turn updates work better know restart phone fast'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b009bce-aff3-41ee-9dde-e9950ea97bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# converting reviews into bag of words\u001b[39;00m\n\u001b[1;32m      3\u001b[0m vec \u001b[38;5;241m=\u001b[39m CountVectorizer(min_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m vec\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m vec\u001b[38;5;241m.\u001b[39mtransform(X)  \n\u001b[1;32m      7\u001b[0m Y \u001b[38;5;241m=\u001b[39m vec\u001b[38;5;241m.\u001b[39mtransform(Y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1339\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m        Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# converting reviews into bag of words\n",
    "\n",
    "vec = CountVectorizer(min_df = 10, ngram_range=(1,3))\n",
    "vec.fit(X)\n",
    "\n",
    "X = vec.transform(X)  \n",
    "Y = vec.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320f157-e308-4834-b291-09d8c9abfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting reviews into bag of words\n",
    "\n",
    "# vec = CountVectorizer(min_df = 10, ngram_range=(1,3))\n",
    "# vec.fit(inputtrain['cleanedreview_3'].values)\n",
    "\n",
    "# inputtrain = vec.transform(inputtrain['cleanedreview_3'].values)  \n",
    "# inputtest = vec.transform(inputtest['cleanedreview_3'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8cf6b8a6-73dd-4e44-abe6-22a71ce38d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57527, 29053), (14382, 29053))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputtrain.shape, inputtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e753edd4-a77b-4155-b97e-6475985b8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, tuple)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputtrain.shape) , type(inputtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "94d8522f-cc5a-4958-b1dd-0f51cf0a8afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m inputtrain\u001b[38;5;241m.\u001b[39mto_array()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65a07c18-76fe-4396-a50e-7d2d6242114c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57527, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23280a00-9070-431c-9659-7c7266d60ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sig = 1/(1+ exp(-z))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75f7abb5-b3ef-4250-b122-8395d62568ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sig = 1/(1+ exp(-z))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bb8788e-6949-4278-90ed-eed6f34b161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x,y):\n",
    "    lr = 0.01\n",
    "    n_iters = 1000\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x.shape\n",
    "   \n",
    "    num_samples, num_features = x.shape             #X = [m x n],   Y = [m x 1]\n",
    "    print(\"0\")\n",
    "    weights = np.random.rand(num_features)          #W = [n x 1],   p = [m x 1]\n",
    "    #bias = mp.ones(num_samples,1)          #b = bias\n",
    "\n",
    "    z= dot(x,weights)      # z = [m x 1]\n",
    "\n",
    "    p = np.ones(num_samples,1)    # p = [m x 1]\n",
    "    for i in range(num_samples):\n",
    "        z_ith = z(i) + b\n",
    "        p_ith = sigmoid(z_ith)\n",
    "        p(i) == p_ith\n",
    "\n",
    "    # cost function  L = A + B\n",
    "    for i in range(n_iters):\n",
    "        dw = dot(x.T,(p-y))    #[n x 1]\n",
    "        db = sum(p- y)\n",
    "        weights = weights - lr * dw\n",
    "        bias = bias - lr* db\n",
    "\n",
    "    # for i in range(5):\n",
    "    #     print(weights(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a062062-e3b2-4e76-81af-07b161cbd9d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fit(inputtrain, outputtrain)\n",
      "Cell \u001b[0;32mIn[91], line 8\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[1;32m      6\u001b[0m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 8\u001b[0m num_samples, num_features \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape             \u001b[38;5;66;03m#X = [m x n],   Y = [m x 1]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(num_features)          \u001b[38;5;66;03m#W = [n x 1],   p = [m x 1]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "fit(inputtrain, outputtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6965d4f-a03e-4c19-ae75-6090d6274175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
